{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranathakur1/DPO-finetuning-with-LoRA/blob/main/DPO_finetuning_with_LoRA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1wdOZItikCA"
      },
      "outputs": [],
      "source": [
        "!pip install datasets trl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DYmH__3is-W"
      },
      "outputs": [],
      "source": [
        "#doanload the dataset\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"Anthropic/hh-rlhf\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cmWmyELmcCA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "\n",
        "for split, ds in dataset.items():\n",
        "    ds.to_json(f\"data/Anthropic_{split}.json\", orient=\"records\", lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mb1odNyNnRV3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Load Anthropic HH JSON file using pandas to handle JSON Lines format\n",
        "hh_data = pd.read_json(\"/content/data/Anthropic_test.json\", lines=True).to_dict(orient=\"records\")\n",
        "\n",
        "# Subsample 3000 records\n",
        "import random\n",
        "random.seed(42)\n",
        "hh_sample = random.sample(hh_data, 3000)\n",
        "\n",
        "print(f\"Sampled {len(hh_sample)} records for DPO training.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9V8U4bjnOP8"
      },
      "outputs": [],
      "source": [
        "#preprocessing the dataset to make data DPO ready\n",
        "dpo_data = []\n",
        "\n",
        "for i, example in enumerate(hh_sample):\n",
        "    # Extract the full chosen and rejected conversation\n",
        "    chosen_text = example['chosen'].strip()\n",
        "    rejected_text = example['rejected'].strip()\n",
        "\n",
        "    # Split by lines to identify turns\n",
        "    chosen_lines = chosen_text.split(\"\\n\")\n",
        "    rejected_lines = rejected_text.split(\"\\n\")\n",
        "\n",
        "    # Identify last human turn as the point where assistant responds next\n",
        "    # Assume last \"Human:\" line in chosen is the last user input\n",
        "    last_human_index = max([idx for idx, line in enumerate(chosen_lines) if line.startswith(\"Human:\")])\n",
        "    prompt_lines = chosen_lines[:last_human_index+1]\n",
        "\n",
        "    # The chosen reply is the assistant response **after the last human turn**\n",
        "    chosen_reply = \"\\n\".join(chosen_lines[last_human_index+1:]).replace(\"Assistant:\", \"\").strip()\n",
        "    rejected_reply = \"\\n\".join(rejected_lines[last_human_index+1:]).replace(\"Assistant:\", \"\").strip()\n",
        "\n",
        "    # Combine context into a single prompt string\n",
        "    prompt = \"\\n\".join(prompt_lines).strip()\n",
        "\n",
        "    # Skip examples where chosen or rejected is empty\n",
        "    if not chosen_reply or not rejected_reply:\n",
        "        continue\n",
        "\n",
        "    # Append to DPO-ready list\n",
        "    dpo_data.append({\n",
        "        \"prompt\": prompt,\n",
        "        \"chosen\": chosen_reply,\n",
        "        \"rejected\": rejected_reply\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNUmPFMWnVwr"
      },
      "outputs": [],
      "source": [
        "#get the subset of dataset\n",
        "dpo_data_small = random.sample(dpo_data,200)\n",
        "\n",
        "dpo_data_small\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRvCrVKMOEcR"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "# hh_sample is currently a list of dicts\n",
        "hh_dataset = Dataset.from_list(hh_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qYiAadYQiog"
      },
      "outputs": [],
      "source": [
        "# To inspect the first record of a datasets.Dataset, you can access it by index\n",
        "hh_dataset[0]\n",
        "\n",
        "# Alternatively, if you want the pandas DataFrame behavior, convert it first:\n",
        "# hh_dataset.to_pandas().head(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#essential imports\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from trl import DPOTrainer\n",
        "from torch import float32\n",
        "from datasets import Dataset # Import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from trl import DPOTrainer\n",
        "import json, random"
      ],
      "metadata": {
        "id": "B8w_wfoU8B-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set configuration\n",
        "os.environ[\"USE_BF16\"] = \"0\"  # disable bf16\n",
        "os.environ[\"USE_FP16\"] = \"1\"  # disable fp16\n",
        "\n",
        "\n",
        "# Load model\n",
        "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\",offload_folder=\"offload\",dtype=torch.float16,)\n",
        "model.gradient_checkpointing_disable()\n",
        "model.config.use_cache = True"
      ],
      "metadata": {
        "id": "KWj-VOqO8aAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# LoRA\n",
        "lora_config = LoraConfig(\n",
        "    r=4,\n",
        "    lora_alpha=8,\n",
        "    target_modules=[\"q_proj\",\"v_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "35NUheE88d1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert dpo_data_small to a datasets.Dataset object\n",
        "dpo_dataset_m = Dataset.from_list(dpo_data_small)\n",
        "\n"
      ],
      "metadata": {
        "id": "OhYKx_Gg8h3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGYMzpk5FE-E"
      },
      "outputs": [],
      "source": [
        "#train with DPO trainer\n",
        "\n",
        "from trl import DPOConfig, DPOTrainer\n",
        "\n",
        "\n",
        "dpo_config = DPOConfig(\n",
        "    learning_rate=2e-5,\n",
        "    max_length=256,   # truncate sequences to reduce memory\n",
        "    beta=0.1,\n",
        ")\n",
        "\n",
        "trainer = DPOTrainer(\n",
        "    model=model,\n",
        "    ref_model=None,\n",
        "    args=dpo_config,\n",
        "    train_dataset=dpo_dataset_m,\n",
        "    peft_config=lora_config\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btUTKL6FVd7h"
      },
      "outputs": [],
      "source": [
        "#save model\n",
        "trainer.model.save_pretrained(\"lora-adapter\")\n",
        "tokenizer.save_pretrained(\"lora-adapter\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTt4JjE4V1jh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7B0PgtL6Vpcx"
      },
      "outputs": [],
      "source": [
        "#inferencing- load base model and newly trained lora adapter\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from peft import PeftModel\n",
        "\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
        "model = PeftModel.from_pretrained(base_model, \"lora-adapter\")  # LoRA weights loaded dynamically\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ymjqn0ZjWe_K"
      },
      "outputs": [],
      "source": [
        "#Infer from the model\n",
        "inputs = tokenizer(\"Explain what LoRA fine-tuning is in simple terms for a product manager.\", return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "#outputs = model.generate(**inputs)\n",
        "outputs = model.generate(\n",
        "    **inputs,\n",
        "    max_new_tokens=50,   # ðŸ‘ˆ CRITICAL\n",
        "    do_sample=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ntqvusNWrS4"
      },
      "outputs": [],
      "source": [
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOmfuUCY6lXfl99g0oSXcxt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}